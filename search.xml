<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[基于tensorflow的最简单的强化学习入门 part0 - Q学习和神经网络]]></title>
    <url>%2Fz_post%2F20190924-Part-0%E2%80%94Q-Learning-Agents%2F</url>
    <content type="text"><![CDATA[本文翻译自 Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks， 作者是 Arthur Juliani，原文链接。 We’ll be learning how to solve the OpenAI FrozenLake environment. Our version is a little less photo-realistic. 在本强化学习系列教程中，我们将要探讨一系列称为Q-Learning的增强学习算法。与接下来的三章(Part1-3)介绍的基于策略(policy-base)的增强学习算法有所不同。 我们将从实现一个简单查找表算法开始，然后展示如何使用Tensorflow来实现等效的神经网络。考虑到上述安排，我们需要回顾基础知识，所以将这一篇视为本系列的第0部分。希望通过这个系列的教程，我们在理解Q-learning之后，能够结合policy gradient和Q-learning方法构建更好的增强学习网络。（如果你对策略网络更感兴趣或者你已经有一些Q-learning的经验，那么你可以从这里开始阅读）&nbsp; 策略梯度算法(policy gradient)试着学习某个函数，该函数可以直接把状态(state)映射为动作(action)的概率分布。Q-learning和策略梯度算法不一样，它试着学习在每个状态下对应的值，并且依赖该状态执行某一个动作。虽然两种方法最终都允许我们给定情况下采取特定的行动，但是实现该目的的方法是不相同的。你也许已经听说深度Q-learning可以玩atari游戏，我们将要在这里讨论和实现这些更复杂和强大的Q-learning算法。 Tabular Approaches for Tabular Environment(表格算法) ​ The rules of the FrozenLake environment 在本教程中，我们将要尝试使用OpenAI gym解决FrozenLake问题。OpenAI gym提供了一个简单的环境，使初学者可以在他们提供一系列游戏中尝试他们的方法。比如FrozenLake，该游戏环境包括一个4*4的网络格子，每个格子可以是起始块，目标块、冻结块或者危险块。我们的目标是让Agent学习从开始块到目标快而不陷入危险块。]]></content>
      <categories>
        <category>Reinforcement Learning</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Reinforcement Learning</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日记]]></title>
    <url>%2Fz_post%2F20190217-moods%2F</url>
    <content type="text"><![CDATA[很真实地欣赏着自己的心偶然间我与你面对面坐下来而你只是说出两个字明天现在我们俩只能在静寂中煎熬悲哀于瞬息之间其实人生并不重要和遥远的童年一样在那恬美爱情的时候我们梦想着每一种不同质的东西面对一个梦萧萧的秋季看见有生命力的枯叶或在沉默之中开口为你描述故事的主角只是每次要等到经历最困难的时候我们才能学会如何去歪曲生命的定义岁月是没有承诺的我们靠各种努力才能建立起毫无价值的精神财富在透明的景色里一层一层将自己包装起来]]></content>
      <categories>
        <category>moods</category>
      </categories>
      <tags>
        <tag>moods</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文本相似度计算]]></title>
    <url>%2Fz_post%2F20190116-textSimilar%2F</url>
    <content type="text"><![CDATA[在网页点击、推荐等众多NLP任务中，常常需要用到文本去重或者相似计算。本文介绍3种常用的方式：shingling、simhash和bloom filter。 一、shingling]]></content>
      <categories>
        <category>原理</category>
      </categories>
      <tags>
        <tag>相似度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[资源分享]]></title>
    <url>%2Fz_post%2F20190113-doc-recommend%2F</url>
    <content type="text"><![CDATA[推荐两份写的比较好的关于HMM(隐马尔可夫链)和LDA的PDF资料，后续资料持续更新 1、点击下载HMM学习最佳范例 2、点击下载LDA数学八卦 3、点击下载2018DataFun技术分享合集 4、点击下载2018阿里巴巴-数字经济下的算法力量 5、点击下载2018美团点评技术年货ai篇 6、点击下载2018携程技术年度合辑 7、点击下载微软亚洲研究院刘铁岩博士《learning to rank for information retrieval》 8、今日推荐排序算法经典教材，微软亚洲研究院的刘铁岩博士的《learning to rank for information retrival》随便推荐lambdaMART相关的博客：lambdaMART原理以及ranklib源码解析 9、大数据相关，内容较大，选择下载 10、自然语言处理相关点击下载]]></content>
      <categories>
        <category>docs</category>
      </categories>
      <tags>
        <tag>docs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习资料]]></title>
    <url>%2Fz_post%2F20190228-Python-Books%2F</url>
    <content type="text"><![CDATA[Python学习相关资料 Python学习相关资料点击下载]]></content>
      <categories>
        <category>Books</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[What I have done this year]]></title>
    <url>%2Fz_post%2F20181231-annua-summary%2F</url>
    <content type="text"><![CDATA[2018年可谓人生一大转折点，这年中结束了长达二十年的求学生涯摇身一变就要两肩扛砖，为一口吃喝而奔波。前半年忙论文忙答辩除了忙碌还是忙碌，不过心情还是极好的，毕竟对面长达三年身心折磨的结束还是很期待的；忘记与学校分手的第几天起，喜欢一个人…啊，呸，从七月的第一个日出那天起入职培训过渡到项目，渐渐开始融入万千互联网农民工的大军中。 一、源 其实昨天晚上我就在想我是不是也要跟个俗，写一个年度总结，纠结了很久最终还是想着这重要的一年还是要留下点什么吧。我想写写工作吧，学校留下的，大概也只有师兄姐弟妹之间的一些东西了。 二、关于工作 当初还是有那么几个工作机会摆在我面面前的，对于最后的选择我还是满意的，一来我比较喜欢现在组内的工作氛围，大家都比较照顾我；二是能够做我喜欢做的事情，也能学到很多东西；最后也能离家很近，有很多熟悉的朋友都还在。 学习 刚入职场的新人，学习总是重要的环节，不管是专业知识，工程能力还是项目沟通能力等等。 1、刚进公司，我是在数据科学团队的。这边主要做一些研究性质的事情，这段时间我的重心主要是一些理论学习。开始我没有想到这边主要做的是nlp一类的项目，而我在这一块算是比较欠缺的（毕竟我是一个学物理的，找工作的时候又看得比较杂，广而不精），所以很多时候的在看论文、看代码、逛技术博客，那段特别感谢赵xx哥和朱x兄带我。后来DS团队合并到搜索推荐组了，赵哥也走了。 2、说实话刚到搜索这边的时候，我还是比较担心的，毕竟这边工程上的事情很多，而我在这一块可能需要补的东西更多，好在老大家林哥比较照顾我，让我还是继续做之前的东西，也总是替我背锅。但研究项目终究需要工程化应用才能产生价值，这段时间非常感谢凯哥，总是很耐心的指导我一些工程上的流程和细节，总体过得也算顺利。后来朱兄和凯哥也走了。 3、那段时间走了好多人，在学校习惯了身边总是那些熟悉的面孔，突然很不适应这种状况，但后来慢慢的也习惯了。 收获 既然有学习，当然就有收获的啦。这半年我做的一个主要项目是一个与文本分类相关的事情。项目从研究、选模型到落地应用持续了好几个月，与加州大学某分校有合作。 1、在这个项目过程中，理论上学习到了比较多的内容，从CNN到Transform的特征提取方式，从word embeding到BERT框架的预训练框架均有所进一步认识。 2、 3、项目方沟通过程中，加强了与业务方的沟通能力，了解业务对模型，对工程的影响。 4、最终，模型成功应用于重要环节，在效果上相比加州大学提高了一倍，这一点我还是很满意的。 不足 自身的不足还是很明显的，特别是以后接触更多的项目，欠下的东西会越发的凸显出来。 1、Java忘记得差不多了，很多工程上的东西还没学。 2、很多基础算法的推导也渐渐模糊了。 3、身上的肉，嗯，好像还是那么多。 三、写在最后 这一年，准确说是半年大概就是这么个情况，有所获有欠缺，来年继续努力，查漏补缺。目前行业的发展有这么一个段子：“2019年可能会是过去十年里最差的一年，但却是未来十年里最好的一年”。革命尚未结束，同志仍需努力，诸君共勉！！ 2018.12.31莫坤东]]></content>
      <categories>
        <category>summary</category>
      </categories>
      <tags>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask的异步及多线程]]></title>
    <url>%2Fz_post%2F20181201-Flask-skill%2F</url>
    <content type="text"><![CDATA[作为著名Python web框架之一的Flask，具有简单轻量、灵活、扩展丰富且上手难度低的特点，因此成为了机器学习和深度学习模型上线跑定时任务，提供API的首选框架。众所周知，Flask默认不支持非阻塞IO的，当请求A还未完成时候，请求B需要等待请求A完成后才能被处理，所以效率非常低。但是线上任务通常需要异步、高并发等需求，本文总结一些在日常使用过程中所常用的技巧。 一、前沿 异步和多线程有什么区别？其实，异步是目的，而多线程是实现这个目的的方法。异步是说，A发起一个操作后（一般都是比较耗时的操作，如果不耗时的操作就没有必要异步了），可以继续自顾自的处理它自己的事儿，不用干等着这个耗时操作返回。实现异步可以采用多线程技术或则交给另外的进程来处理,详解常见这里。 二、实现方法 Flask启动自带方法 采用gunicorn部署 1、Flask中自带方法实现 run.py #!/usr/bin/env python # -*- coding: utf-8 -*- # @Time : 2018-12-01 16:37 # @Author : mokundong from flask import Flask import socket from time import sleep myhost = socket.gethostbyname(socket.gethostname()) app = Flask(__name__) @app.route('/job1') def some_long_task1(): print("Task #1 started!") sleep(10) print("Task #1 is done!") @app.route('/job2') def some_long_task2(arg1, arg2): print("Task #2 started with args: %s %s!" % (arg1, arg2)) sleep(5) print("Task #2 is done!") if __name__ == '__main__': app.run(host=myhost,port=5000,threaded=True) app.run(host=xxx,port=xx,threaded=True)中threaded开启后则不需要等队列。 2、gunicorn部署 Gunicorn 是一个高效的Python WSGI Server,通常用它来运行 wsgi application 或者 wsgi framework(如Django,Paster,Flask),地位相当于Java中的Tomcat。gunicorn 会启动一组 worker进程，所有worker进程公用一组listener，在每个worker中为每个listener建立一个wsgi server。每当有HTTP链接到来时，wsgi server创建一个协程来处理该链接，协程处理该链接的时候，先初始化WSGI环境，然后调用用户提供的app对象去处理HTTP请求。关于gunicorn的详细说明，可以参考这里。 使用命令行启动gunicorn有两种方式获取配置项，一种是在命令行配置，一种是在配置文件中获取。 run.py #!/usr/bin/env python # -*- coding: utf-8 -*- # @Time : 2018-12-01 17:00 # @Author : mokundong from flask import Flask from time import sleep app = Flask(__name__) @app.route('/job1') def some_long_task1(): print("Task #1 started!") sleep(10) print("Task #1 is done!") @app.route('/job2') def some_long_task2(arg1, arg2): print("Task #2 started with args: %s %s!" % (arg1, arg2)) sleep(5) print("Task #2 is done!") if __name__ == '__main__': app.run() 命令行配置gunicorn --workers=4 --bind=127.0.0.1:8000 run:app 更多配置见官网 配置文件获取配置 gunicorn_config.py #!/usr/bin/env python # -*- coding: utf-8 -*- # @Time : 2018-12-01 17:10 # @Author : mokundong import os import socket import multiprocessing import gevent.monkey gevent.monkey.patch_all() myhost = socket.gethostbyname(socket.gethostname()) debug = False loglevel = 'info' hosts = get_host_ip() bind = hosts+":5000" timeout = 30 #超时 pidfile = "log/gunicorn.pid" accesslog = "log/access.log" errorlog = "log/debug.log" daemon = True #意味着开启后台运行，默认为False workers = 4 # 启动的进程数 threads = 2 #指定每个进程开启的线程数 worker_class = 'gevent' #默认为sync模式，也可使用gevent模式。 x_forwarded_for_header = 'X-FORWARDED-FOR' 启动命令如下 gunicorn -c gunicorn_config.py run:app 三、补充1、关于线程的补充 在工作中我还遇到一种情况，当一个请求过来后，我需要两种回应，一个是及时返回app运行结果，第二个响应是保存数据到日志或者数据库。往往我们在写数据的过程中会花销一定的时间，导致结果返回会有所延迟，因此我们需要用两个线程处理这两个任务，那么我们如下处理。 run.py #!/usr/bin/env python # -*- coding: utf-8 -*- # @Time : 2018-12-01 17:20 # @Author : mokundong from flask import Flask,request from time import sleep from concurrent.futures import ThreadPoolExecutor executor = ThreadPoolExecutor(2) app = Flask(__name__) @app.route('/job') def run_jobs(): executor.submit(some_long_task1) executor.submit(some_long_task2, 'hello', 123) return 'Two jobs was launched in background!' def some_long_task1(): print("Task #1 started!") sleep(10) print("Task #1 is done!") def some_long_task2(arg1, arg2): print("Task #2 started with args: %s %s!" % (arg1, arg2)) sleep(5) print("Task #2 is done!") if __name__ == '__main__': app.run() 2、关于获取IP的补充 上述代码中通过获取hostname，然后再通过hostname反查处机器的IP。这个方法是不推荐的。因为很多的机器没有规范这个hostname的设置。另外就是有些服务器会在 /etc/hosts 中添加本机的hostname的地址，这个做法也不是不可以，但是如果设置成了 127.0.0.1，那么获取出来的IP就都是这个地址了。这里给出一种优雅的方式获取IP，利用 UDP 协议来实现的，生成一个UDP包，把自己的 IP 放如到 UDP 协议头中，然后从UDP包中获取本机的IP。 #!/usr/bin/env python # -*- coding: utf-8 -*- # @Time : 2018-12-01 17:30 # @Author : mokundong # 可以封装成函数，方便 Python 的程序调用 import socket def get_host_ip(): try: s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) s.connect(('8.8.8.8', 80)) ip = s.getsockname()[0] finally: s.close() return ip 总结当然推荐使用gunicorn部署多线程，Flask自带的，emmmm，测试玩儿玩儿吧。在写作过程中才发现自己知识漏洞不是一般多，共勉！]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于ubuntu16.04的hadoop2.7.2 完全分布式集群搭建]]></title>
    <url>%2Fz_post%2F20170329-ubuntu-hadoop%2F</url>
    <content type="text"><![CDATA[此文主要是记录了基于ubuntu16.04的hadoop2.7.2 完全分布式集群搭建的配置环境搭建 一、hosts修改/etc/hosts 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647master节点host----------------------127.0.0.1 localhost192.168.64.100 master192.168.64.101 slave1192.168.64.102 slave2192.168.64.103 slave3192.168.64.104 slave4-----------------------slave1节点host-----------------------127.0.0.1 localhost127.0.1.1 slave1192.168.64.100 master192.168.64.101 slave1192.168.64.102 slave2192.168.64.103 slave3192.168.64.104 slave4-----------------------slave2节点host-----------------------127.0.0.1 localhost127.0.1.1 slave2192.168.64.100 master192.168.64.101 slave1192.168.64.102 slave2192.168.64.103 slave3192.168.64.104 slave4-----------------------slave3节点host-----------------------127.0.0.1 localhost127.0.1.1 slave3192.168.64.100 master192.168.64.101 slave1192.168.64.102 slave2192.168.64.103 slave3192.168.64.104 slave4-----------------------slave4节点host-----------------------127.0.0.1 localhost192.168.64.100 master192.168.64.101 slave1192.168.64.102 slave2192.168.64.103 slave3192.168.64.104 slave4 二、environment环境变量修改12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697hadoop-env.sh-----------------export JAVA_HOME=/usr/local/jvm/jdk-----------------slaves：-----------------slave1slave2slave3---------------------core-site.xml：--------------------&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:8020&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;------------------------- hdfs-site.xml：------------------------&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;slave4:50090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name1,file:/usr/local/hadoop/tmp/dfs/name2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data1,file:/usr/local/hadoop/tmp/dfs/data2&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;----------------------------------------------------------mapred-site.xml(复制mapred-site.xml.template,再修改文件名)----------------------------------------------------------&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;Master:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;Master:19888&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;----------------------yarn-site.xml---------------------&lt;configuration&gt; &lt;!-- Site specific YARN configuration properties --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;------------------------- 三、namenode -format1hdfs namenode -format 四、shell命令1、分发复制xsync1234567891011121314151617181920#!/bin/bashpcount=$#if (( pcount&lt;1 )); then echo no args; exit;fi#p1=$1;fname=`basename $p1`#echo fname=$fname;pdir=`cd -P $(dirname $p1); pwd`#echo pdir=$pdircuser=`whoami`for(( host=1; host&lt;5;host=host+1)); do echo ----------------s$host---------- rsync -rvl $pdir/$fname $cuser@slave$host:$pdirdone rsync xxx 2、集群操作命令xcall 12345678910111213141516171819#!/bin/bashpcount=$#if (( pcount&lt;1 )); then echo no args; exit;fi#p1=$1;fname=`basename $p1`#echo fname=$fname;echo --------master--------$@cuser=`whoami`for(( host=1; host&lt;5;host=host+1)); do echo ---------slave$host-------- ssh slave$host $@done xcall rm -rf xxxxcall jps…]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过外网远程ssh访问虚拟机上的linux服务器]]></title>
    <url>%2Fz_post%2F20170328-sshIntoLinuxServerInlntranet%2F</url>
    <content type="text"><![CDATA[相信很多人都有远程访问虚拟机需求，比如异地访问虚拟机上的linux服务器、搭建的集群等等，仅仅需要配置几个映射端口即可 一、将虚拟机ip映射到主机某一端口1、将linux虚拟机的ip地址调整为静态ipvmware软件–&gt;编辑–&gt;虚拟网络编辑器–&gt;查看NAT模式下的DHCP设置–&gt;下图中画圈的ip区间即为自己可选静态ip段 12345678打开 /etc/network/interfaces 文件添加如下片段iface ens33 inet staticaddress 192.168.64.100 //填写范围从起始ip到结束ip之间netmask 255.255.255.0 //子网掩码gateway 192.168.64.2 //参考NAT设置--&gt;网关ipdns-nameservers 192.168.64.2auto ens33 2、将虚拟机22端口开放给主机某一个端口vmware软件–&gt;编辑–&gt;虚拟网络编辑器–&gt;查看NAT模式下的NAT设置–&gt;添加填写主机端口，一般填写较大4位数（较小位数一般系统占用，如22、80等等端口）虚拟机端口填写22，及ssh连接端口 上图就是我分别将三台虚拟机的ssh端口映射到主机的三个端口 二、将主机端口映射到外网1、查看主机本地ip 2、将主机本地ip映射到路由器外网ip浏览器输入–&gt; 192.168.1.1 –&gt;转发规则–&gt;虚拟服务器–&gt;添加 服务端口是路由器开放给本地主机ip的端口（宜大不宜小）内部端口是本地开放给虚拟机ip的端口（端口号同1.2中主机端口） 3、查看路由器ip地址 外网ip xxx.xx.xxx.xxx 三、验收到外网打开xshell 键入 意不意外，惊不惊喜！！ 我这里路由器没有设置动态ip、所以更换网络环境还得换路由ip，不过也不麻烦了，换掉就是。]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>SSH</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea中通过java程序直接调用python文件]]></title>
    <url>%2Fz_post%2F20170225-runPythonInJava%2F</url>
    <content type="text"><![CDATA[项目用python开发时大量引入了外包，当需要在java中使用该代码时考虑要么转成java语言（太麻烦），要么打包成jar（没找到合适的方法），参考了一些java调用python文件方法，并不适合我目前开发的环境，下面给出idea下直接调用的方法。 一、在idea中添加python添加环境变量 二、测试python文件（test.py） 1234567from __future__ import print_functionfrom sklearn import datasetsfrom sklearn.linear_model import LinearRegressionimport matplotlib.pyplot as pltX, y = datasets.make_regression(n_samples=100, n_features=1, n_targets=1, noise=10)plt.scatter(X, y)plt.show() idea中java代码 123456789101112131415161718192021222324package com.mkd.stringdemo;import java.io.BufferedReader;import java.io.InputStreamReader;public class testDemo &#123; public static void main(String[] args)&#123; try&#123; System.out.println("start"); Process pr = Runtime.getRuntime().exec("python d:\work\test\test.py"); BufferedReader in = new BufferedReader(new InputStreamReader(pr.getInputStream())); String line; while ((line = in.readLine()) != null) &#123; System.out.println(line); &#125; in.close(); pr.waitFor(); System.out.println("end"); &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 三、运行结果 后记：为了开发效率确实这样子很方便，但是为了工程效率还是老老实实改成java吧。]]></content>
      <categories>
        <category>skill</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
